{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression for prediction\n",
    "\n",
    "Signification des Ã©moticones :\n",
    "- ðŸŒž : documentations importantes\n",
    "- ðŸ‘€ : documentations intÃ©ressantes Ã  connaÃ®tre\n",
    "- ðŸŒš : en complÃ©ment\n",
    "- (vide) : Ã  vous de voir\n",
    "\n",
    "-------\n",
    "\n",
    "For the remainder of the module we will look at using linear regression in a more algorithmic/computer science/machine learning context. In this notebook we will take a more detailed look at conducting linear regression in `scikit-learn`, you will:\n",
    "* write your own code to compute MSE\n",
    "* Learn what training and testing sets are\n",
    "* Use `scikit-learn` to perform a multiple linear regression\n",
    "* Evaluate your results\n",
    "* Create a model to predict housing prices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assesing model accuracy\n",
    "\n",
    "We always must evaluate how 'good' our model is in order to understand how it performs. One common measure of accuracy (or error) for a regression type problem is **Mean Squared Error (MSE)**. This can be calculated using the following formula:\n",
    "\n",
    "<div style=\"font-size: 120%;\">  \n",
    "$$ MSE = \\frac{1}{n} \\sum_{i=1}^n (y_i âˆ’ \\hat{f}(x_i))^2, $$\n",
    "</div>\n",
    "\n",
    "where $y_i$ is the true values and $\\hat{f}(x_i)$ is the predicted values by our model over $n$ samples.\n",
    "\n",
    "### Exercise 1: write a function to calculate MSE\n",
    "\n",
    "Given the lists of true values and predictions write a function that calculates the MSE of this data. \n",
    "\n",
    "\n",
    "HINT\n",
    "* using numpy arrays will make this much easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_values = [13.9, 20.3, 2.1, 8.8, 5.2]\n",
    "predicted_vals = [14.3, 18.9, 3.4, 8.9, 5.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE evaluation in sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Scikit-Learn` provides a function to calculate MSE (as well as other useful performance metrics) so that you dont have to carry around your function to all the different projects you work on. We can use this to evaluate our function and check that we got the correct answer in the exercise above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7720000000000011"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(true_values, predicted_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1**: Other evaluation metrics\n",
    "* Find at least 2 other metrics that exist in `Scikit-Learn` that can be used in regression problems.\n",
    "* Calculate the errors of these on the hypothetical data we used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing sets\n",
    "\n",
    "When building models for prediction we are most interested in building a model that will generalise well to new sets of data that we will encounter in the future. Strictly speaking what we have calculated above is a *training MSE*, which means that the calculation of MSE was performed on the same data samples the model was fitted to. \n",
    " \n",
    "One good way to asses whether our model will be useful on new data sets is to fit our model only to a subset of the data, and then use new data the model has not seen to produce a prediction which we can evaluate. We saw this process in the previous notebook when we introduced `scikit-learn` and Logistic Regression.\n",
    "\n",
    "Here is another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "diabs = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, total serum cholesterol\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, total cholesterol / HDL\n",
      "      - s5      ltg, possibly log of serum triglycerides level\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "print(diabs.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabs.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabs.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X = pd.DataFrame(diabs.data, columns=diabs.feature_names)\n",
    "y = diabs.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  \n",
       "0 -0.002592  0.019908 -0.017646  \n",
       "1 -0.039493 -0.068330 -0.092204  \n",
       "2 -0.002592  0.002864 -0.025930  \n",
       "3  0.034309  0.022692 -0.009362  \n",
       "4 -0.002592 -0.031991 -0.046641  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into a test and training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting a linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MSE: 3006.0733911079724\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# fit model to training data\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict y values for testing data set\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# evaluate MSE\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "print('test MSE: {0}'.format(mse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use this model to predict values on the train set, and evaluate the MSE. Comparing the two MSE scores gives us information on whether the model is overfitting or not. Normally we would compare these scores with other types of models (for example *support vector machines* or *random forests*...) that we have built in order to understand which model is best for the particular problem we are trying to solve. We almost always expect the *training error* to be lower than the *test error* (i.e. our performance reduces (or MSE increases) slightly when we move to new data the model has not seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training MSE: 2864.886357101882\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = model.predict(X_train)\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print('training MSE: {0}'.format(mse_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: interpreting MSE\n",
    "\n",
    "MSE is not particularly intuitive to help understand how well your model predicts. In order to interpret how well our model is doing we could convert MSE to something with similar units to the target variable by taking the square root. This would be **Root Mean Squared Error** or **RMSE**.\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div style=\"font-size: 120%;\">\n",
    "$$ RMSE = \\sqrt{MSE}$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 54.82766994053251\n"
     ]
    }
   ],
   "source": [
    "rmse_test = np.sqrt(mse_test)\n",
    "print('RMSE: {0}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do some simple descriptive stats on the target variable for the training set, we can see that our model is finding a solution on average within one standard deviation of the variance of the target. This type of analysis can give us some confidence whether our model is remotely useful or not!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean (standard deviation) values of target variables in train set: 150.93655589123867 (76.63854952919398)\n"
     ]
    }
   ],
   "source": [
    "mean  = np.mean(y_train)\n",
    "std = np.std(y_train)\n",
    "print('Mean (standard deviation) values of target variables in train set: {0} ({1})'.format(mean, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE, MSE, R2 squared: further reading\n",
    "\n",
    "* ðŸŒš https://stats.stackexchange.com/questions/242787/how-to-interpret-root-mean-squared-error-rmse-vs-standard-deviation\n",
    "* ðŸŒš https://setosa.io/ev/ordinary-least-squares-regression/\n",
    "* ðŸ‘€ https://medium.com/analytics-vidhya/mae-mse-rmse-coefficient-of-determination-adjusted-r-squared-which-metric-is-better-cd0326a5697e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between predictor variables (or features)\n",
    "\n",
    "Correlation between two (or more) predictive variable means that there is a statistical relation between these two variables. This can be causal or not. When two variables are highle correlated (> 0.5), than they are collinear. This can be problematic.In the presence of collinearity between two or more predictors, it is difficult to isolate the impact of each of that predictor on the response. Multicollinearity has an impact on the coefficients and p values of those coefficients. But it does not impact the precision of the predictions. So depending on the goal (first notebook, classical statistics or machine learning) it is desirable to take out features that are correlated. Also in the case of ML, when we have a dataset with a large number of predictors, taking out variables that are collinear helps to reduce the dimensions and make a simplar more stable model.\n",
    "\n",
    "\n",
    "(Further reading, see page 73, 74, 99 of ILS book).\n",
    "ðŸŒš https://datascience.stackexchange.com/questions/24452/in-supervised-learning-why-is-it-bad-to-have-correlated-features\n",
    "\n",
    "Two methods:\n",
    "* make a correlation matrix and decide what variables to leave out. (0.1 = moderate, 0.5 = large)\n",
    "* Use variance inflaction factor method to leave out columns / features (if VIF > 5, leave out column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEdCAYAAADwwTuSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAnWklEQVR4nO3deZxcVZn/8c+3mwBhE9nDoqBGEBQQQoABFRAYwB+TYUS2GQYUJuIYF1BHxn3gJ+owjhsgBkRwQJZRAlEjiyATNzYhJKwhAkoIw6IYVs3Sz/xxT5ObSnX37dS9Vbcq3/frdV9Vd3vuqeqknz73nHuOIgIzM7Mi+jpdADMz6x5OGmZmVpiThpmZFeakYWZmhTlpmJlZYU4aZmZWmJOGmVmNSbpA0pOS7h5ivyR9XdI8SbMl7ZLbd5CkB9K+U8soj5OGmVm9XQgcNMz+g4HxaZkMfBNAUj9wdtq/PXC0pO1bLYyThplZjUXETOCPwxwyCfhuZG4G1pc0DpgIzIuIhyJiEXBZOrYlq7UaoBucpK0rf+z97IeurDS+YqDS+Ivm3lFpfID+DTerNH7f2utVGv8PW+xWaXyAjZ6YVWn8pc88VWn8gZdeqDQ+wJitxlcav++1E9VqjNH8zvkWv3svWQ1h0NSImDqKy20BPJpbn5+2Ndu++yjiNrVKJA0zs3bqH0XaiYGYCowmSTRqdrUYZntLnDTMzErWr5YrK6MxH9gqt74lsABYfYjtLXGbhplZyfpVfCnBdOAfUy+qPYCFEfE4cBswXtI2klYHjkrHtsQ1DTOzkpVZ05B0KbAPsJGk+cBngTEAEXEuMAM4BJgHvAi8O+1bImkKcC3QD1wQEfe0Wh4nDTOzkq3eV17SiIijR9gfwPuH2DeDLKmUxknDzKxkJd12qiUnDTOzkrW5IbytatEQLukqSb+RdI+kyWnbCZLmSrpJ0nmSzkrbN5b0A0m3pWWvzpbezGx5faNYuk1dahrviYg/ShoL3Cbpx8CngV2A54AbgbvSsV8DvhIRv5D0KrJGnjd0otBmZs30ck2jLknjg5IOS++3Ao4F/ici/ggg6b+B16f9+wPba9kPZT1J60bEc/mAqcYyGeAtbMD2rFvxRzAzy7hNo0KS9iFLBHtGxIuSbgIeYOjaQ1869qXh4qbH8KdCe4YRMTMbVGbvqbqpwy21VwDPpISxHbAHsBbwNkmvlLQa8M7c8dcBUwZXJO3czsKamY2kXyq8dJs6JI1rgNUkzQZOB24GHgPOAG4BfgrcCyxMx38QmJDGjb8XOKn9RTYzG1qbnwhvq47fnoqIv5CN974cSbdHxNRU05hGVsMgIp4GjmxvKc3MiuvGGkRRHU8aw/icpP2BNckSxlWdLY6ZWTHdWIMoqrZJIyI+2ukymJmtjF5uCK9t0jAz61auaZiZWWFu0zAzs8Jc0+hyVc/fDfD+1/xdpfG/8eTMSuOvNm7rSuMDLH3NxErja+Fjlcafdv/TlcYHOO6Zlqc7GNaYHfasNH7/S89WGh9g8cavqzT+GiXEcE3DzMwKc03DzMwKG9NXh+emq+GkYWZWMvVwVcNJw8ysZH0lJg1JB5FNCdEPnB8RX2zY/zHg79PqamSDvW6cppt4hGx6iaXAkoiY0Gp5nDTMzEqm/nJuT0nqB84GDgDmk803ND0i7h08JiLOBM5Mxx8KnDw4rUSybxp+qRROGmZmJSvx9tREYF5EPAQg6TJgEtkgrs0cDVxa1sWb6d3WGjOzDunrV+FlBFsAj+bW56dtK5C0FnAQ8IPc5gCuS9NpT27hI72sNjUNSWsDVwBbkt27Ox2YB/wnsA7wNHA88CJwK/A3EfGApEuBGyPivE6U28ysUf+Y/sLH5mcZTaamSeQAmmWVoSaVOxT4ZcOtqb0iYoGkTYDrJd0fES099FWbpEGWIRdExDsAJL0C+AkwKSKeknQk8PmIeI+kKcCFkr4GvNIJw8zqZDS3p/KzjDYxn2wK7EFbAguGOPYoGm5NRcSC9PqkpGlkt7taShp1uj01B9hf0pckvYXsi3ojWXacBXyK7AsjIq5Px58NnNgsmKTJkm6XdPt5l1b/RLiZ2SD19xVeRnAbMF7SNpJWJ0sM01e4XvZH9tuAq3Pb1pa07uB74EDg7lY/W21qGhExV9KuwCHAF4DrgXsiYoVxDyT1kXUrewnYgCwbN8Z7OXsvffgOzxFuZm1TVpfbiFiS7qxcS3bb/oKIuEfSSWn/uenQw4DrIuKF3OmbAtOUDWmyGvC9iLim1TLVJmlI2hz4Y0RcLOl5snt8G0vaMyJ+LWkM8PqIuAc4GbgP+ARwQTpmcedKb2a2jEqcTyMiZgAzGrad27B+IXBhw7aHgJ1KK0hSm6QBvAk4U9IAsBh4H7AE+Hqqeq0GfFXSYrJbUhMj4jlJM8luXX22Q+U2M1tO/+rFG8K7TW2SRkRcS1YFa/TWJtvekDvvlMoKZWa2EjyMiJmZFdZX0hPhdeSkYWZWMtc0zMyssL4SG8LrxknDzKxkZQ1YWEdOGmZmJetf3UmjqykGKr9G1XN4f2CTZp3IyvPl7zV9sL5UawxU+3OIJYsqjT+mf+dK4wMsfnKoESLK8cK871Yaf+zGG1QaH+D3159Zafztzr+q5RiuaZiZWWFlTsJUN04aZmYlK/OJ8Lpx0jAzK5mf0zAzs8L8nIaZmRXWN6Z3f7V2vA4laWtJKzXGu6TNJX2/7DKZmbWir7+v8NJtujodplmpDu90OczM8nq5y21dPtlqki6SNFvS9yWtJekRSWdI+nWagW8XSddK+u3gBCSt1FLMzKpS4sx9tVOXEm9LNpn6jsCzwD+n7Y+mmft+TjbByOHAHsBpnSikmVkR6usrvHSbupT40Yj4ZXp/MbB3ej84F+4c4JaIeC4ingL+LGn94QLm5wif6jnCzayN+lYfU3jpNnVp02icw3tw/S/pdSD3fnB92LLn5wgfeOh2zxFuZm3T14U1iKLq8sleJWnP9P5o4BedLIyZWSvKbNOQdJCkByTNk3Rqk/37SFooaVZaPlP03JVRl6RxH3CcpNnABsA3O1weM7OVVlbSkNQPnA0cDGwPHC1p+yaH/jwidk7LaaM8d1Q6fnsqIh4h+0CNts4dcyFZQ/jg+uC+p4E3VlU2M7OVUWID90RgXkQ8BCDpMmAScG/F5w6pLjUNM7OeMZqaRr7TTlom50JtATyaW5+ftjXaU9Jdkn4iaYdRnjsqHa9pmJn1mv7Vi/9qzXfaaaLZIFaNHXvuAF4dEc9LOgS4Chhf8NxRc03DzKxkJT6nMR/YKre+JbDcTF0R8WxEPJ/ezwDGSNqoyLkrwzUNM7OSlfik923AeEnbAI8BRwHHLHctaTPgiYgISRPJKgN/AP400rkrw0nDzKxkZSWNiFgiaQpwLdAPXBAR9wwOpRQR55KNlPE+SUuAl4CjIiKApue2WqZVImksmntH5ddYbdzWlcaveg7vjxxzfqXxAc66Y0Kl8fs33LzS+HustX6l8QHGardK4/fNvbPS+O2w6a7bdboIIypzeJB0y2lGw7Zzc+/PAs4qem6rVomkYWbWTn39/Z0uQmWcNMzMStY3it5T3aZ3P5mZWYd04+i1RTlpmJmVrBvnySiq1p/MkyyZWTfq5UmYXNMwMyuZb0911mqSLgLeDMwF/pFswK3LgX3TMcdExLwOlc/MbDlabfVOF6Ey3ZAOh5oK9tmImEjWP/mrHSqbmdmK+vqKL12mG0o81FSwl+Ze91zhLDOzDlF/f+Gl23RD0hhqKtgY5pjlhhv+9oyZlRXOzGwFff3Fly7TDUljqKlgj8y9/rrxpIiYGhETImLCCYe8tQ3FNDNLnDQ6aqipYNeQdAvwIeDkThXOzKxRiUOj106te08NNRWsJICzI+Lf2l0mM7MR9XDvqVonDTOzbtSNNYiiujJpRMTWnS6DmdmQurCtoqiuTBpmZrXmpGFmZkV14/MXRTlpmJmVzW0a3a1/w80qv8bS10ysNP4aAwOVxq96KlaAKbucVGn8169TbY+VKfN/VWl8gEcvvazS+GPWXrPS+BvttUel8QHW22nvkQ/qsDLHnpJ0EPA1snm+z4+ILzbs/3vg42n1eeB9EXFX2vcI8BywFFgSES3/R18lkoaZWVuVVNOQ1A+cDRwAzAdukzQ9Iu7NHfYw8LaIeEbSwcBUYPfc/n0j4ulSCoSThplZ6VReQ/hEYF5EPAQg6TJgEtlI3wBERL4KfDOwZVkXb6Z3b7yZmXXKKIYRyY+Tl5bJuUhbAI/m1uenbUM5AfhJbj2A6yT9piHuSnNNw8ysbKO4PRURU8luKTWjZqc0PVDalyxp5Bt99oqIBZI2Aa6XdH9EtDSCq5OGmVnJNKa0hvD5wFa59S2BBStcT9oROB84OCL+MLg9Ihak1yclTSO73dVS0ui621OSpkiaJykkbdTp8piZraC8UW5vA8ZL2kbS6sBRwPT8AZJeBVwJHBsRc3Pb15a07uB74EDg7lY/WjfWNH4J/Ai4qcPlMDNrqqyxpyJiiaQpwLVkXW4viIh7JJ2U9p8LfAbYEDgnDeY62LV2U2Ba2rYa8L2IuKbVMtU6aaTseAVZlawfOD0iLk/7Olk0M7OhlTiMSETMAGY0bDs39/5E4MQm5z0E7FRaQZJaJw3gIGBBRLwDQNIrOlweM7ORqevu/BdW9082B9hf0pckvSUiFhY9Md+N7fxp11ZYRDOzBuorvnSZWtc0ImKupF2BQ4AvSLouIk4reO7L3dgW3za9aRc1M7MqRF+tf7W2pNafTNLmwB8j4mJJzwPHd7hIZmYj6+E217rXjd4E3CppFvBJ4P9L+qCk+WSN47Mlnd/JApqZraCvr/jSZWpd04iIa8m6muXdDny9A8UxMyskurCtoqhaJw0zs67kpGFmZoW5IdzMzIry7SkzMyvOScPMzArr4S63q0TS6Ft7vcqvoYWPVRo/liyqNH7/hptXGh+qn8N77vPVfkf3vzCm0vgAi+5dYdTrUr3plH+oNL7WGFtpfADWWLv6a7TKNQ0zMyvKbRpmZlZcf+/+au3dT2Zm1imuaZiZWWFOGmZmVpTbNGpE0iXABGAxcCvw3ohY3NlSmZnl9HDS6MZPdgmwHdkIuGNpMs2hmVlHScWXEUPpIEkPSJon6dQm+yXp62n/bEm7FD13ZdS6pjHcHOFp/61pn5lZbZQ1CZOkfuBs4ABgPnCbpOkRcW/usIOB8WnZHfgmsHvBc0et1kmDYeYIlzQGOBb4UIfKZmbWXHm3pyYC8yLiIQBJlwGTgPwv/knAdyMigJslrS9pHLB1gXNHre63p4abI/wcYGZE/LzZifk5ws+74odtKayZGUBIhZf876q0TM6F2gJ4NLc+P22jwDFFzh21Wtc0hpojXNJngY2B9w5z7stzhC+99ybPEW5mbROj+I2T/13VRLNGj8boQx1T5NxRq3XSaDZHuKQTgb8G3h4RA50toZnZigZGkzWGNx/YKre+JdA4QNlQx6xe4NxRq3XSIOshdaakAbIutu8DbgZ+B/xaWc+DKyPitM4V0cxseUvLu7dxGzBe0jbAY8BRwDENx0wHpqQ2i92BhRHxuKSnCpw7arVOGkPMEV7rMpuZRUk1jYhYImkK2e/BfuCCiLhH0klp/7nADLJb+POAF4F3D3duq2XyL2Azs5INlNiKGhEzyBJDftu5ufcBvL/oua1y0jAzK1kv97xx0jAzK1mZNY26cdIwMytZWW0adeSkYWZWshJ7T9XOKpE0/rDFbpVfY9r9T1caf0z/zpXG32Ot9SuNDzBl/q8qjV/1HN7nbLFTpfEBfvGRsyqN/09jt680/nYbrVNpfIAH//eFSuNP2ab1GL49ZWZmhfn2lJmZFdbLQ1U4aZiZlayHKxpOGmZmZStx7KnacdIwMyuZe0/ViKRvk80RLmAucHxEPN/ZUpmZLdPDFY3aT8LUzMkRsVNE7Aj8HpjS6QKZmeUNEIWXblPrpCFpbUk/lnSXpLslHRkRz6Z9AsbS28O8mFkXiii+dJu6355qOke4pO+QDQV8L/CRzhXPzGxFvfxwX61rGgwxR3hEvBvYHLgPOLLZifl5d7974QXtK7GZrfKWRhReuk2taxpDzRGe9i2VdDnwMeA7Tc59ed7dJxe+0H0/GTPrWl2YCwqrddJoMkf4uyW9LiLmpTaNQ4H7O1tKM7Pl+TmNzmmcI/z9wEWS1iPrcnsX2bzhZma1sbSHxxGpddIYYo7wvTpRFjOzotpV05C0AXA5sDXwCHBERDzTcMxWwHeBzciGxZoaEV9L+z4H/BPwVDr8E2mK2CHVvSHczKzrtLEh/FTghogYD9yQ1hstAT4SEW8A9gDeLyk/Rv5XImLntIw4n3itaxpmZt1ocfvGEZkE7JPeXwTcBHw8f0BEPA48nt4/J+k+YAuyRxZGzTUNM7OSDUQUXvKPB6Rl8igutWlKCoPJYZPhDpa0NfBm4Jbc5imSZku6QNIrR7qgaxpmZiUbzW2n/OMBzUj6KVl7RKNPjqZMktYBfgB8eHBkDeCbwOlkI2ucDnwZeM9wcZw0zMxKVuYT4RGx/1D7JD0haVxEPC5pHPDkEMeNIUsYl0TElbnYT+SOOQ/40UjlWSWSxkZPzKr8Gsc9c0+l8Rc/uaDS+GNV/Tzqj156WaXxF91b7XdU9fzdAHt/udrxN/d7rNo5wl994IRK4wPsvnhJtRfY84yWQyxt3zgi04HjgC+m16sbD0jPtH0buC8i/rNh37jB21vAYcDdI13QbRpmZiUbTZtGi74IHCDpQeCAtI6kzSUN9oTaCzgW2E/SrLQckvb9u6Q5kmYD+wInj3TBVaKmYWbWTovbVNOIiD8Ab2+yfQHZ8EtExC/IHoZudv6xo72mk4aZWcnaeHuq7Zw0zMxK1stjT3Vtm4akb6RBDM3MamVpFF+6TVfWNCRNANbvdDnMzJpxTaNDmk33KqkfOBP4l06Xz8ysmcVLo/DSbepe02g23esUYHp6mKWjhTMza6aXaxp1TxpzgP+Q9CWyJxV/C7yLZQN0mZnVTjdO41pUrW9PRcRcYFey5PEFsnHfXwfMk/QIsJakec3OzQ8CNvXyFR6SNDOrzMBAFF66Ta1rGk2mez0+IjbL7X8+Il7X7Nz8IGADc3/ZfT8ZM+taXdhUUVitkwYrTvfqqV3NrPbcptEhQ0z3mt+/ThuLY2ZWyKIeniS81knDzKwbeRgRMzMrzEnDzMwKc9IwM7PCnDTMzKywRUvcEN7Vlj7zVOXXGLPDnpXGf2HedyuN3zf3zkrjA4xZe81K47/plH+oNP4/ja12qlSofjrWsy+7t9L4p0/cttL4AAt/+1il8dcvIYZrGmZmVpiThpmZFdaupCFpA+ByYGvgEeCIiHimyXGPAM8BS4ElETFhNOfn1XrsKTOzbrRkIAovLToVuCEixgM3pPWh7BsROw8mjJU4H3DSMDMr3dKBKLy0aBJwUXp/EfC3VZ/v21NmZiUbzTAikiYDk3ObpqYBV4vYNCIeB0hzDG0yxHEBXCcpgG/l4hc9/2VdlzQkXQi8DViYNh0fEbM6ViAzswajqUHkR+RuRtJPgc2a7PrkKIq0V0QsSEnhekn3R8TMUZz/sq5LGsnHIuL7nS6EmVkzZTaER8T+Q+2T9ISkcamWMA54cogYC9Lrk5KmAROBmUCh8/Nq3abRbI7wTpfJzGwkbWzTmA4cl94fB6ww41z6Pbru4HvgQODuouc3qnXSYNkc4TtFxBuBa9L2z0uaLekrktboYPnMzFawdGCg8NKiLwIHSHoQOCCtI2lzSTPSMZsCv5B0F3Ar8OOIuGa484dT96QxB9hf0pckvSUiFgL/CmwH7AZsAHy82Yn56V7Pv+q69pXYzFZ57appRMQfIuLtETE+vf4xbV8QEYek9w+lP7x3iogdIuLzI50/nFq3aUTEXEm7AocAX5B0XUSclnb/RdJ3gI8Oce7LjUuLb7mqdx/PNLPa+YvHnuqMZnOE5xptRNan+O5hg5iZtZmHEemcZnOEXyJpY0DALOCkzhXPzGxFThodMsQc4ft1oixmZkU5aZiZWWFOGmZmVtgSN4SbmVlRA65pmJlZURFOGmZmVlC4ptHdBl56ofJr9L/0bKXxx268QaXx22GjvfaoNL7WGFtp/O02WqfS+ACvPnDCyAe1oOo5vD99yrRK4wP85xX/XPk1WuXbU2ZmVlj0bju4k4aZWdmWjmISpm7jpGFmVjK3aZiZWWFOGmZmVthAD3e5rft8GitQ5vOS5kq6T9IHO10mM7O8GIjCS7fpxprG8cBWwHYRMZAmSjczq41uTAZF1TpppPlsrwC2BPqB08mGRz8mIuvUFhEjToRuZtZOvdx7qu63p5rNEf5a4Mg0letPJI3vbBHNzJYXA8WXVkjaQNL1kh5Mr69scsy2kmbllmclfTjt+5ykx3L7DhnpmnVPGs3mCF8D+HNETADOAy5oduJyc4T/8MY2FtnMVnUDA1F4adGpwA0RMR64Ia0vJyIeiIidI2JnYFfgRSD/6P5XBvdHxIyRLljr21PN5ggH5gM/SIdMA74zxLkvzxH+l5su6d0bjGZWO21s05gE7JPeXwTcBHx8mOPfDvw2In63shesdU0jzRH+YkRcDPwHsAtwFctm73sbMLczpTMza66Nvac2jYjHAdLrSB2DjgIubdg2RdJsSRc0u73VqNY1DZrPET6PbJ7wk4HngRM7WD4zsxWMpiFc0mRgcm7T1HSnZHD/T4HNmpz6ydGUSdLqwN8A/5rb/E2yDkaRXr8MvGe4OLVOGkPMEQ7wjnaXxcysqNHUIPK30ofYv/9Q+yQ9IWlcRDwuaRwwXG/Sg4E7IuKJXOyX30s6D/jRSOWt9e0pM7Nu1MaG8OnAcen9ccDVwxx7NA23plKiGXQYcPdIF3TSMDMrWUQUXlr0ReAASQ8CB6R1JG0u6eWeUJLWSvuvbDj/3yXNkTQb2Bc4eaQL1vr2lJlZN2pX76mI+ANZj6jG7QvIep0Orr8IbNjkuGNHe00nDTOzknnmPjMzK2xgyaJOF6Eyq0TSGLNV9SONLN74dZXG//31Z1Yaf9Ndt6s0PsB6O+1d7QXWWLvS8A/+b/Vzze++eEml8Rf+9rFK47dj/u5Tjjin0vjnxr+0HCMGlpZQknpaJZKGmVk7xVInDTMzK8g1DTMzK8xJw8zMCnPSMDOzwtx7KkfS58gGClwPmBkRPx3m2JuAj0bE7QVj7wxsXmRMdzOzuhpwTWNFEfGZMguS7AxMAJw0zKxr9fLtqUJjT0n6pKQH0hC926ZtF0o6PL3/jKTbJN0taaok5U7/B0m/SvsmpuPXTmO33ybpTkmT0rC9p5FN5TpL0pHNjkvn7yDp1nTcbE/5amZ1EgNLCy/dZsSaRpo57yjgzen4O4DfNBx2VkSclo7/L+D/AT9M+9aOiL+S9FayqVnfSDYO/I0R8R5J6wO3Aj8FPgNMiIgpKdYZjcelxHUS8LWIuCQlm/6V/QLMzMrWy89pFKlpvAWYFhEvRsSzZEPxNtpX0i2S5pDNqrdDbt+lABExE1gv/fI/EDhV0iyy6QnXBF7VJO5Qx/0a+ISkjwOvjoiXGk/MzxE+9bJpjbvNzCozsGRR4aXbFG3TGHL0LUlrAueQ1RAeTQ3law5zbgAC3hkRDzTE2r0xfLPjgPsk3UI2GdO1kk6MiBuXu0huYpOB397au6OHmVntdONtp6KK1DRmAodJGitpXeDQhv2DCeJpSesAhzfsPxJA0t7AwohYSDYb3wcG2z4kvTkd+xywbu7cpsdJeg3wUER8nazms2OBz2Fm1hYxMFB46TYj1jQi4g5JlwOzgN8BP2/Y/6c0TeAc4BHgtoYQz0j6FVkX3cG5Z08HvgrMTgnhEbJ2kJ+x7HbUF4Y57kiyBvbFwP+SNaCbmdVCL9c0Ct2eiojPA58fZv+ngE812b7PEMe/BLy3yfY/Ars1bG523BfIkoqZWe2s8knDzMyK88N9ZmZW2MDi7usVVVShh/vMzKy4dj3cJ+ldku6RNCBpwjDHHZQe0J4n6dTc9g0kXS/pwfT6ypGu6aRhZlayNj4Rfjfwd2S9XJuS1A+cDRwMbA8cLWn7tPtU4IaIGA/ckNaH5aRhZlaydiWNiLivyXNsjSYC8yLioYhYBFwGTEr7JgEXpfcXAX9b5KJeGhZgcrdfo9vj98Jn8HdUj2u04zO0Wj7g9twy6vKSjZgxYYh9hwPn59aPJRv6CeBPDcc+M9K1XNNobnIPXKPb47fjGt0evx3X8GeoWERMjYgJuWVqfr+kn6YBXxuXSUPFbKAm21Z6lAz3njIzq7GI2L/FEPOBrXLrWwIL0vsnJI2LiMcljQOeHCmYaxpmZr3tNmC8pG3SqOBHsWzg2enAcen9ccDVIwVz0mhu6siH1P4a3R6/Hdfo9vjtuIY/Q41JOkzSfGBP4MeSrk3bN5c0AyAilgBTyMbyuw+4IiLuSSG+CBwg6UHggLQ+/DVT44eZmdmIXNMwM7PCnDTMzKwwJw0zMyvMSaOBpLU7XQYzs7py0kgk/ZWke8l6FyBpJ0nnlBj/hIb1fkmfLSn2Fel1jqTZuWWOpNllXCPFf42kH0p6WtKTkq5OsyhWRlIpPV/S9/1eSadL2qth3wpzwaxE/LUk/Yukj0laU9LxkqZL+vc0o2XpJM0tOd6OufdjJH0qfYYzJK1VQvwpkjZK718naaakP0m6RdKbWo2fu85rJa2R3u8j6YOS1i8r/qrOvaeSNOf44cD0iBicVvbuiHhjSfG/B6wPnABsCHwH+J+I+GgJsQcfznl1s/0R8btWr5GuczPZwGeXpk1HAR+IiMa53Ucbd4OhdgF3RcSWrcRP1zgfWAu4lWwYhf+JiFPSvjsiYpcW418BPAqMBbYldW0kmx55s4g4tsX4z7HsKd7BJ3zXAl4EIiLWayV+usbL34OkL7Ps3+nfAhtGxD+2GP+eiNghvf8x2dAW0yTtA3w+IvYa7vxRXGcWMAHYmqyb6XRg24g4pIz4qzo/EZ4TEY+m6cgHlTaTSkQcI+lIsmlxXwSOjohflhT78fT6OwBJ61HNz1YR8V+59YslTSkh7lNkUwnnv/xI65uUEB9gYkTsCCDpLOAcSVcCRzdcd2W9PiKOSNMSPw7sHxEh6efAXSXEvxB4BfCxiHgCQNLDEbFNCbEH5b+HtwO7RcRiSTMp5zPk/01uEhHTACLiJknrlhB/0EBELJF0GPDViPiGpDtLjL9Kc9JY5lFJfwVEemryg6RbVWWQNB74EPAD4A3AsZLujIgXS7zGe8nmS3+JZX+VBlDWLaSfSfpXsppGkM3V/uPBmkJk0/WujIeAt0fE7xt3SHp0ZQvbYPXBN+lhp8np9uCNQGm3j1KimBGpCp/WW67OR8QHJO0KXCrpKuAsWhg/aAivSL9o+4A1ImJxunYpnwH4vqQLyf6NTpP0YeBKsgS1ws++BYslHU32hPOhaduYEuOv2jo9wmNdFmAj4BLgCbLxVy4mq5KXFf9+sr8+IfuL7iPAPSV/hgeBjSr8jh5Oy0NpeTi/rYW47wd2GmLfB0oq+8XAQU22nwAsLiH++cA6Tba/FvhFiT+DPrI/aH4OLCj55/udhmXTtH0zsjkXyrjG8cAtwNPAc8C9wBnAK0r8HNsDXyerzQNsA5xa5ne1Ki8dL8CqsgDrNdk2vuRrXAOsVeFnGJuS3TSyvxBPBtYsMf67gHXT+0+na+xS8mfIX+NTZV+jSfxpDDFkdQvx1wPGAZ+p8Dtar8Lv6Ihc/MGf85tL/gxjydoxSovpJX23nS5AXZb0l0njcjowqaT4mwLfBq5J69sDJ5T8Gd4MzAK+lf8cJca/Iv1FvW9appKNY1NW/Nnpde/0l/Qk4JaSv6NKr9Hm+DN74Dsq/TOQ3ZJ6AHg4re9M1sGltO9oVV7c5XaZNcn+cT2Ylh2BDYATJH21hPgXkvXkGJfW5wIfLiFu3rfI7tHfDPwmt5Rl24g4MSJ+lpbJZD2FyjLY8eAdwDcj4mpybRFdco12xj+3B76jKj7D58hmq/sTQETMIrtFZSVwQ/gyrwP2i6yRFEnfBK4jG/lxTgnxN4qIK1JDMpH17iitd1ayJFI30orcKWmPiLgZQNLuQCk9wJLHJH0L2B/4UuprX/YfNlVfo9vjt+MaVcdfEhELG3pC+tmCkrimscwWQP5p8LWBzSNiKfCXEuK/IGlD0j9eSXsAC0uIm/czSZMljZO0weDSatDcQ4K7A7+S9Iikh4FfA29tNX7OEWS1sYMi4k9kNb2PlRi/Hdfo9vjtuEbV8e+WdAzQL2m8pG8Avyox/irND/clyp7Y/hTZXLsi+2V4Bln30s9FREv/qCXtAnwDeCNwN7AxcHhElPnE9sM0+YsqIlrqcjvUQ4O5+KU8PGhWhvT0+ieBA9Oma4HTI6KMP/5WeU4aOZI2J3ta+H6ymsb8iJhZUux3kf3j3Qp4J9lf7Z+OiDvKiJ+uMRb4Z7IGxiBrxDw3Il4q6xpmdSfpXRHx3yNts5XjpJFIOpHs4bstyXog7QH8OiL2Kyn+7IjYUdLeZDWYLwOfiBaH4Gi4xhXAs2TPm0D2tPP6EXFEWdcwq7tmw8KUMVSMZdwQvsyHgN2AmyNiX0nbAf9WYvwVeoxI+lyJ8SHr3bRTbv1nksoY/sGs9iQdDBwCbCHp67ld6wFLOlOq3uOG8GX+HBF/BpC0RkTcT7ndSQd7jBwBzKio18udqYEdqKR3k1mdLQBuB/7M8l3OpwN/3cFy9RTfnkokTQPeTfbsxH7AM8CYKGlkzNQ4dxAwJyIelDQOeFNEXFdC7DlkbRhjyBLd79P6q4F7o6SRes26gaQxZHdRXhURD3S6PL3GSaMJSW8jG1H0mohY1OnyjMS9m8yWkXQo8B/A6hGxjaSdgdMi4m86W7Le4KRhZj1F0m/I7hbcFMvmxpkdaWh8a43bNMys1yyJiLIfnLXEvafMrNcs90Q42VDyfiK8JK5pmFmv+QCwA9nwP5eSPbv04U4WqJe4TcPMelKa9jgi4rlOl6WXuKZhZj1F0m6pG/psYI6ku9JUuVYC1zTMrKekEZnfHxE/T+t7A+e491Q5XNMws17z3GDCAIiIX5DNR24lcO8pM+sJafoBgFvTkD2Xko2McCTZlAdWAt+eMrOeIOlnw+yOskasXtU5aZiZWWG+PWVmPUfSO8ie1VhzcFtEnNa5EvUON4SbWU+RdC5ZO8YHyKZufhfZiM9WAt+eMrOekpslc/B1HeDKiDhwxJNtRK5pmFmveSm9vihpc2AxsE0Hy9NT3KZhZr3mR5LWB84E7iDrdnt+R0vUQ3x7ysx6VppWeU0PlV4eJw0z6wmS9ouIGyX9XbP9EXFlu8vUi3x7ysx6xVuBG4FDyW5JDVJad9IogZOGmfWK5ySdAtxNliSUtvt2SomcNMysV6yTXrcFdgOuJkschwIzO1WoXuM2DTPrKZKuA945OPmSpHWB/46Igzpbst7g5zTMrNe8CliUW18EbN2ZovQe354ys17zX2TDo08ja884DLios0XqHb49ZWY9J82t8Za0OjMi7uxkeXqJk4aZmRXmNg0zMyvMScPMzApz0jAzs8KcNMzMrLD/AwVv8ANXYfqHAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Correlation matrix\n",
    "df = pd.concat([X, pd.Series(y)], axis=1)\n",
    "df = df.rename(columns={0:'diabetes'})\n",
    "\n",
    "import seaborn as sns\n",
    "_ = sns.heatmap(df.corr(), cmap=\"RdBu_r\", vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above matrix we see that bmi (predictor) is strongly correlated to diabetes (response). As a predictor, bmi is strongly related to bp. To make a regression model we could take out bp without impacting the accuracy of the prediction of diabetes. This results in a simpler and smaller model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.203786</td>\n",
       "      <td>s1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39.194379</td>\n",
       "      <td>s2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15.402352</td>\n",
       "      <td>s3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.890986</td>\n",
       "      <td>s4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.076222</td>\n",
       "      <td>s5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         VIF features\n",
       "4  59.203786       s1\n",
       "5  39.194379       s2\n",
       "6  15.402352       s3\n",
       "7   8.890986       s4\n",
       "8  10.076222       s5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variance Inflation Factor\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "variables = X\n",
    "variables.shape\n",
    "vif = pd.DataFrame()\n",
    "vif['VIF'] = [variance_inflation_factor(variables.values,i) for i in range(variables.shape[1])]\n",
    "vif['features'] = variables.columns\n",
    "vif[vif['VIF']>5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leaving out the above columns should not impact the precision of prediction. But it results in a smaller and simpler model. Also, the std error and confidence interval of the coefficients should be smaller. But be carefull, deleting all features with high collinearity, may lead to deleting the feature that is the best predictor for the response. So first check the correlation between features you want to delete and the (cor)relation with the response variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Linear regression prediction of house prices\n",
    "\n",
    "The California housing market is booming and, as it is the home of silicon valley, the housing company **Homes4You** have decided they want to use new data science techniques to aid their business. They want you to build a predictive model that provides the median house price for each local area across the state (These local areas are often called *'blocks'*). They will use this to help guide their agents in how to price houses.\n",
    "\n",
    "They have gathered a data set with numerous features to assist in building your model. However, they prefer to include as few features as possible to minimize the time their agents will spend collecting data in the future.\n",
    "\n",
    "\n",
    "Your mission is to apply a regression model to predict housing prices in California.\n",
    "* Import the data the company has collected using the sklearn function `fetch_california_housing`\n",
    "* Make a heatmap of the correlation coefficiencts between the variables\n",
    "* Split the data into a training and testing set\n",
    "* Build a linear regression model using all the variables available and print the train and test MSE scores.\n",
    "* Try building other models with different combinations of variables. Print the train and test MSE scores of at least 2 of these models.\n",
    "* Provide a recommendation to Homes4You of which variables you would include in the model.\n",
    "* Print the train and test **RMSE** scores of your final model and explain in a few sentences to Homes4You how well your model is performing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3: Explain this to your neighbour...**\n",
    "* The training and test errors are quite close. What does this mean? \n",
    "\n",
    "\n",
    "\n",
    "<details><summary>HINT</summary><br>\n",
    "HINT: think in terms of if we were to apply this fitted model to new data the model has not seen.\n",
    "\n",
    "</details>\n",
    "\n",
    "* If your MSE & RMSE results are different to those of your peers (even when using the same features and model), why might this be? \n",
    "\n",
    "\n",
    "\n",
    "**Task 4:**\n",
    "* Try to load the 'boston house price' (do some further research, what is the issue here?). \n",
    "* Try to load 'Linnerrud' data set that comes with sklearn? Try to build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
